{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy \n",
    "import cv2\n",
    "import hashlib\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[449, 330, 122, 149, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "f = open('./wider_face_split/wider_face_train_bbx_gt.txt')\n",
    "imgpath = f.readline().rstrip()\n",
    "imgpath = os.path.join('./WIDER_train/images/', imgpath)\n",
    "no_of_faces = f.readline().rstrip()\n",
    "image = cv2.imread(imgpath)\n",
    "for i in no_of_faces:\n",
    "    details = f.readline().rstrip().split()\n",
    "    details = list(map(int, details))\n",
    "    print(details)\n",
    "    cv2.rectangle(image, (details[0], details[1]), (details[0]+details[2], details[1]+details[3]), (255,0,0), 2)\n",
    "cv2.imshow(\"img\", image); cv2.waitKey(0); cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Analysis\n",
    "\n",
    "Checks to find out the following:\n",
    "1. Whether all images from annotation files are actually present or not\n",
    "2. The number of images with zero faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images written in annotation file:  12880\n",
      "Number of images actually found:  12880\n",
      "Total number of faces:  159420\n",
      "All images from annotations were found in dataset\n",
      "Number of images with Zero faces:  0\n"
     ]
    }
   ],
   "source": [
    "f = open('./wider_face_split/wider_face_train_bbx_gt.txt')\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "no_of_faces= 0\n",
    "while True:\n",
    "    line = f.readline().rstrip()\n",
    "    if not line:\n",
    "        break\n",
    "    elif '.jpg' in line:\n",
    "        if( os.path.isfile(os.path.join('./WIDER_train/images/', line)) ):\n",
    "            count2 += 1\n",
    "        this_no_of_faces = int (f.readline().rstrip())\n",
    "        no_of_faces += this_no_of_faces\n",
    "        count1 = count1 + 1\n",
    "        if (this_no_of_faces == 0):\n",
    "            count3+=0\n",
    "f.close()        \n",
    "print ('Number of images written in annotation file: ',count1)\n",
    "print('Number of images actually found: ', count2)\n",
    "print('Total number of faces: ', no_of_faces)\n",
    "if count1 == count2:\n",
    "    print('All images from annotations were found in dataset')\n",
    "else:\n",
    "    print('Mismatch present')\n",
    "print('Number of images with Zero faces: ', count3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding Box Integrity Check\n",
    "\n",
    "This test is to check whether the face bounding boxes lie outside image dimmensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faceboxes outside image:  0\n"
     ]
    }
   ],
   "source": [
    "f = open('./wider_face_split/wider_face_train_bbx_gt.txt')\n",
    "count1 = 0\n",
    "count2=0\n",
    "no_of_faces= 0\n",
    "\n",
    "while True:\n",
    "    line = f.readline().rstrip()\n",
    "    if not line:\n",
    "        break\n",
    "    elif '.jpg' in line:\n",
    "        no_of_faces = 0\n",
    "        filepath = os.path.join('./WIDER_train/images/', line)\n",
    "        \n",
    "        image = cv2.imread(filepath)\n",
    "        height, width, channel = image.shape        \n",
    "        no_of_faces = int (f.readline().rstrip())\n",
    "        for i in range(no_of_faces):\n",
    "            face_desc = f.readline().rstrip().split()\n",
    "            face_desc = list(map(int, face_desc))\n",
    "            xmin = face_desc[0]\n",
    "            ymin = face_desc[1]\n",
    "            xmax = xmin + face_desc[2]\n",
    "            ymax = ymin + face_desc[3]\n",
    "            if ( (xmax > width) & (ymax > height) ):\n",
    "                count1 += 1\n",
    "            else:\n",
    "                count2 += 1\n",
    "            \n",
    "f.close()        \n",
    "print ('Number of faceboxes outside image: ',count1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF Example and TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/train.tfrecord'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = os.path.join('./output/', 'train.tfrecord')\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(count, total):\n",
    "    pct_complete = float(count) / total\n",
    "    msg = \"\\r- Progress: {0:.1%}  \".format(pct_complete)\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfexample(jpgline,no_of_faces, f):\n",
    "    \n",
    "    filepath = os.path.join('./WIDER_train/images/',jpgline)\n",
    "    filename = jpgline.split('/')[1].encode('utf-8')\n",
    "    \n",
    "    image = cv2.imread(filepath)\n",
    "    height, width, channel = image.shape\n",
    "    \n",
    "    encoded_image_data = open(filepath, 'rb').read()\n",
    "    key = hashlib.sha256(encoded_image_data).hexdigest()\n",
    "    \n",
    "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "    xmaxs = [] # List of normalized right x coordinates in bounding box (1 per box)\n",
    "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "    ymaxs = [] # List of normalized bottom y coordinates in bounding box (1 per box)\n",
    "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "    classes = [] # List of integer class id of bounding box (1 per box)\n",
    "    poses = []\n",
    "    truncated = []\n",
    "    difficult_obj = []\n",
    "    pose = ''\n",
    "    \n",
    "    for x in range(no_of_faces):\n",
    "\n",
    "        details_array = f.readline().rstrip().split()\n",
    "        details_array = list(map(int, details_array))\n",
    "\n",
    "        xmins.append( float(details_array[0]/width) )\n",
    "        xmaxs.append( float((details_array[0]+details_array[2])/width) )\n",
    "        ymins.append( float(details_array[1]/height) )\n",
    "        ymaxs.append( float((details_array[1]+details_array[3])/height) )\n",
    "        classes_text.append(b'face')\n",
    "        classes.append(1)\n",
    "        pose = 'typical' if (int(details_array[-1]) == 0) else 'atypial'\n",
    "        poses.append(pose.encode('utf8'))\n",
    "        truncated.append(int(0))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(int(height)),\n",
    "        'image/width': dataset_util.int64_feature(int(width)),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "        'image/object/difficult': dataset_util.int64_list_feature(int(0)),\n",
    "        'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "        'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "        }))\n",
    "\n",
    "    return tf_example       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Progress: 100.0%  No. of images processed:  12880\n"
     ]
    }
   ],
   "source": [
    "f = open('./wider_face_split/wider_face_train_bbx_gt.txt')\n",
    "writer = tf.io.TFRecordWriter(output_path)\n",
    "count = 0\n",
    "while True:\n",
    "    line = f.readline().rstrip()\n",
    "    if not line:\n",
    "        break\n",
    "    elif '.jpg' in line:\n",
    "        no_of_faces = int(f.readline().rstrip())\n",
    "        if(no_of_faces > 0):\n",
    "            tf_example = create_tfexample(line, no_of_faces, f)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "        count+=1\n",
    "        #print(count)\n",
    "        print_progress(count=count, total=12880)\n",
    "print('No. of images processed: ', count)            \n",
    "writer.close()                 \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
